{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4836fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import PIL\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "\n",
    "# from keras.models import Sequential\n",
    "#Import from keras_preprocessing not from keras.preprocessing\n",
    "# from keras_preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "# from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "# from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Input, Conv2D, ZeroPadding2D, Flatten, AveragePooling2D, Dense, Activation, Add\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "\n",
    "import SciServer.CasJobs as CasJobs # query with CasJobs, the primary database for the SDSS\n",
    "import SciServer.SkyServer as SkyServer # show individual objects through SkyServer\n",
    "import SciServer.SciDrive\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae8370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Helper functions for visualization:\n",
    "def plot_confusion_matrix(y_true, y_pred,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    From scikit-learn: plots a confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    #fixes \"squishing of plot\"\n",
    "    plt.ylim([1.5, -.5])\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "def plot_model_history(history, n_epochs):\n",
    "    '''Plot the training and validation history for a TensorFlow network'''\n",
    "\n",
    "    # Extract loss and accuracy\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1,ncols=2, figsize=(10,5))\n",
    "    ax[0].plot(np.arange(n_epochs), loss, label='Training Loss')\n",
    "    ax[0].plot(np.arange(n_epochs), val_loss, label='Validation Loss')\n",
    "    ax[0].set_title('Loss Curves')\n",
    "    ax[0].legend()\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "\n",
    "    ax[1].plot(np.arange(n_epochs), acc, label='Training Accuracy')\n",
    "    ax[1].plot(np.arange(n_epochs), val_acc, label='Validation Accuracy')\n",
    "    ax[1].set_title('Accuracy Curves')\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    \n",
    "    \n",
    "# # Check balance of labels/data in dataframe\n",
    "\n",
    "def checkBalance(df):\n",
    "    all_labels = df['labels']\n",
    "    all_labels = all_labels.tolist()\n",
    "    balance = df['labels'].value_counts()\n",
    "    print(balance)\n",
    "    for i in range(len(balance)):\n",
    "        print(f'{balance[i]*200/df.size:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50a7177d-7c6a-4ee1-b7ae-91bb8ab56e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PCC-0001</td>\n",
       "      <td>49.2355</td>\n",
       "      <td>41.5722</td>\n",
       "      <td>20.51</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20.80</td>\n",
       "      <td>1.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Likely cluster or background edge-on disk galaxy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PCC-0002</td>\n",
       "      <td>49.2366</td>\n",
       "      <td>41.4013</td>\n",
       "      <td>20.44</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.14</td>\n",
       "      <td>21.96</td>\n",
       "      <td>0.79</td>\n",
       "      <td>...</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Likely cluster or background edge-on disk galaxy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PCC-0003</td>\n",
       "      <td>49.2370</td>\n",
       "      <td>41.4336</td>\n",
       "      <td>21.58</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>22.41</td>\n",
       "      <td>0.07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Likely cluster or background edge-on disk galaxy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PCC-0004</td>\n",
       "      <td>49.2377</td>\n",
       "      <td>41.5285</td>\n",
       "      <td>21.03</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>23.14</td>\n",
       "      <td>0.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Likely background ETG or unresolved source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PCC-0005</td>\n",
       "      <td>49.2380</td>\n",
       "      <td>41.4346</td>\n",
       "      <td>20.27</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.04</td>\n",
       "      <td>21.94</td>\n",
       "      <td>0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Likely cluster or background edge-on disk galaxy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PCC-5433</td>\n",
       "      <td>50.0062</td>\n",
       "      <td>41.2380</td>\n",
       "      <td>20.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.53</td>\n",
       "      <td>3.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Likely background ETG or unresolved source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5433</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PCC-5434</td>\n",
       "      <td>50.0064</td>\n",
       "      <td>41.2568</td>\n",
       "      <td>22.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.29</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Likely cluster or background edge-on disk galaxy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PCC-5435</td>\n",
       "      <td>50.0068</td>\n",
       "      <td>41.6048</td>\n",
       "      <td>21.44</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.02</td>\n",
       "      <td>21.52</td>\n",
       "      <td>0.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Likely cluster or background edge-on disk galaxy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PCC-5436</td>\n",
       "      <td>50.0070</td>\n",
       "      <td>41.3916</td>\n",
       "      <td>21.32</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.10</td>\n",
       "      <td>22.86</td>\n",
       "      <td>0.95</td>\n",
       "      <td>...</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cluster or background LTG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5436</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PCC-5437</td>\n",
       "      <td>50.0089</td>\n",
       "      <td>41.6781</td>\n",
       "      <td>22.36</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.72</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Likely background ETG or unresolved source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5437 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1        2        3      4     5     6     7      8     9   \\\n",
       "0    NaN  PCC-0001  49.2355  41.5722  20.51  0.04  1.44  0.10  20.80  1.07   \n",
       "1    NaN  PCC-0002  49.2366  41.4013  20.44  0.04  2.18  0.14  21.96  0.79   \n",
       "2    NaN  PCC-0003  49.2370  41.4336  21.58  0.04  1.11  0.07  22.41  0.07   \n",
       "3    NaN  PCC-0004  49.2377  41.5285  21.03  0.06  1.08  0.10  23.14  0.69   \n",
       "4    NaN  PCC-0005  49.2380  41.4346  20.27  0.02  1.24  0.04  21.94  0.80   \n",
       "...   ..       ...      ...      ...    ...   ...   ...   ...    ...   ...   \n",
       "5432 NaN  PCC-5433  50.0062  41.2380  20.32   NaN  1.10   NaN  22.53  3.80   \n",
       "5433 NaN  PCC-5434  50.0064  41.2568  22.63   NaN  0.54   NaN  23.29  0.50   \n",
       "5434 NaN  PCC-5435  50.0068  41.6048  21.44  0.02  0.61  0.02  21.52  0.43   \n",
       "5435 NaN  PCC-5436  50.0070  41.3916  21.32  0.07  0.99  0.10  22.86  0.95   \n",
       "5436 NaN  PCC-5437  50.0089  41.6781  22.36  0.04  0.12   NaN  19.72  0.50   \n",
       "\n",
       "      ...    15    16    17    18   19   20  \\\n",
       "0     ...  0.69  0.25  0.63  0.28  NaN  NaN   \n",
       "1     ...  1.53  1.01  1.38  0.97  NaN  NaN   \n",
       "2     ...  1.25  0.71  1.19  0.67  NaN  NaN   \n",
       "3     ...  0.58  0.25  0.42  0.15  NaN  NaN   \n",
       "4     ...  0.70  0.50  0.53  0.48  NaN  NaN   \n",
       "...   ...   ...   ...   ...   ...  ...  ...   \n",
       "5432  ...  0.97  0.83  0.93  0.69  NaN  NaN   \n",
       "5433  ...  1.46  1.12   NaN   NaN  NaN  NaN   \n",
       "5434  ...  0.59  0.41   NaN   NaN  NaN  NaN   \n",
       "5435  ...  1.19  1.07  1.06  0.92  NaN  NaN   \n",
       "5436  ...  0.62  1.49   NaN   NaN  NaN  NaN   \n",
       "\n",
       "                                                    21   22   23  \\\n",
       "0     Likely cluster or background edge-on disk galaxy  NaN  NaN   \n",
       "1     Likely cluster or background edge-on disk galaxy  NaN  NaN   \n",
       "2     Likely cluster or background edge-on disk galaxy  NaN  NaN   \n",
       "3           Likely background ETG or unresolved source  NaN  NaN   \n",
       "4     Likely cluster or background edge-on disk galaxy  NaN  NaN   \n",
       "...                                                ...  ...  ...   \n",
       "5432        Likely background ETG or unresolved source  NaN  NaN   \n",
       "5433  Likely cluster or background edge-on disk galaxy  NaN  NaN   \n",
       "5434  Likely cluster or background edge-on disk galaxy  NaN  NaN   \n",
       "5435                         Cluster or background LTG  NaN  NaN   \n",
       "5436        Likely background ETG or unresolved source  NaN  NaN   \n",
       "\n",
       "                                                     24  \n",
       "0     http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...  \n",
       "1     http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...  \n",
       "2     http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...  \n",
       "3     http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...  \n",
       "4     http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...  \n",
       "...                                                 ...  \n",
       "5432  http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...  \n",
       "5433  http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...  \n",
       "5434  http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...  \n",
       "5435  http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...  \n",
       "5436  http://dc.zah.uni-heidelberg.de/pcc/q/stamp/dl...  \n",
       "\n",
       "[5437 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0 = pd.read_fwf('../PCC_cat.txt', header=None)\n",
    "# df0[21] # 21 is the label entry index\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c89f512-3169-495f-86b0-eb67fcda2cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4754</th>\n",
       "      <td>sdss_ra=49.9154_dec=41.2302.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>sdss_ra=49.4815_dec=41.434.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>sdss_ra=49.5132_dec=41.3783.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>sdss_ra=49.5247_dec=41.4305.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>sdss_ra=49.7345_dec=41.6346.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>sdss_ra=49.9932_dec=41.5479.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5357</th>\n",
       "      <td>sdss_ra=49.9947_dec=41.75.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5373</th>\n",
       "      <td>sdss_ra=49.9967_dec=41.3092.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4501</th>\n",
       "      <td>sdss_ra=49.8825_dec=41.7447.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>sdss_ra=49.9387_dec=41.2544.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                files labels\n",
       "4754  sdss_ra=49.9154_dec=41.2302.png      0\n",
       "1405   sdss_ra=49.4815_dec=41.434.png      0\n",
       "1616  sdss_ra=49.5132_dec=41.3783.png      0\n",
       "1692  sdss_ra=49.5247_dec=41.4305.png      0\n",
       "3312  sdss_ra=49.7345_dec=41.6346.png      0\n",
       "...                               ...    ...\n",
       "5338  sdss_ra=49.9932_dec=41.5479.png      1\n",
       "5357    sdss_ra=49.9947_dec=41.75.png      1\n",
       "5373  sdss_ra=49.9967_dec=41.3092.png      1\n",
       "4501  sdss_ra=49.8825_dec=41.7447.png      1\n",
       "4931  sdss_ra=49.9387_dec=41.2544.png      1\n",
       "\n",
       "[246 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Here we have 7 unique labels:\n",
    "labels = np.unique(df0[21])\n",
    "\n",
    "# access ra and dec from their columns in the dataframe\n",
    "ra = df0[2]\n",
    "dec = df0[3]\n",
    "\n",
    "# want only bright objects above r_mag < 19.4  (the magnitude decreases as brightness increases)\n",
    "bright = np.where(df0[4] <= 19.4)\n",
    "brightDF = df0.iloc[bright].copy()\n",
    "\n",
    "labels = np.unique(brightDF[21])\n",
    "\n",
    "# access ra and dec from their columns in the dataframe\n",
    "ra = brightDF[2]\n",
    "dec = brightDF[3]\n",
    "\n",
    "filenames = []\n",
    "for r, d in zip(ra, dec):\n",
    "    fn = f'sdss_ra={r}_dec={d}.png'\n",
    "    filenames.append(fn)\n",
    "\n",
    "brightDF_reduced = pd.DataFrame({'files' : filenames,\n",
    "                                 'labels': brightDF[21]})\n",
    "\n",
    "\n",
    "# checkBalance(brightDF_reduced)\n",
    "df1 = brightDF_reduced\n",
    "unique_labels = np.unique(df1['labels'])\n",
    "\n",
    "clusterBG_LTG = df1.loc[(df1['labels']==unique_labels[0])]\n",
    "BG_ETG = df1.loc[(df1['labels']==unique_labels[1])]\n",
    "clusterBG_edgeDisk = df1.loc[(df1['labels']==unique_labels[2])]\n",
    "likely_dE_ETGcluster = df1.loc[(df1['labels']==unique_labels[3])]\n",
    "likely_merging = df1.loc[(df1['labels']==unique_labels[4])]\n",
    "poss_dE_ETGcluster = df1.loc[(df1['labels']==unique_labels[5])]\n",
    "weak_bg = df1.loc[(df1['labels']==unique_labels[6])]\n",
    "\n",
    "downSampleDf0 = pd.concat([clusterBG_LTG, # 384\n",
    "                         BG_ETG.sample(frac = 400/3008),\n",
    "                         clusterBG_edgeDisk.sample(frac = 400/1049),\n",
    "                         likely_dE_ETGcluster, # 398\n",
    "                         likely_merging, # 23\n",
    "                         poss_dE_ETGcluster, # 98\n",
    "                         weak_bg # 477\n",
    "                         ])\n",
    "# checkBalance(downSampleDf0)\n",
    "\n",
    "def replace(df, ind):\n",
    "    label = list(df['labels'])[0]\n",
    "    newDf = df.replace(label, str(ind))\n",
    "    return(newDf)\n",
    "\n",
    "\n",
    "# combined 3 and 5\n",
    "second = pd.concat([\n",
    "                    replace(likely_dE_ETGcluster, 1), # old 3\n",
    "                    replace(poss_dE_ETGcluster, 1) # old 5\n",
    "                    ])\n",
    "# combine 0,1,2,6\n",
    "first = pd.concat([replace(clusterBG_LTG, 0), # old 0\n",
    "                   replace(BG_ETG, 0), # old 1\n",
    "                   replace(clusterBG_edgeDisk, 0), # old 2\n",
    "                   replace(weak_bg, 0) # old 6\n",
    "                    ])\n",
    "\n",
    "lenSecond = len(second.index)\n",
    "lenFirst = len(first.index)\n",
    "\n",
    "# df with PCC objects reduced to 0s or 1s\n",
    "downSampleDf1 = pd.concat([first.sample(frac = lenSecond/lenFirst), second])\n",
    "\n",
    "# 0 is background\n",
    "# 1 is dE/ETGcluster\n",
    "downSampleDf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bedb9961-5b19-4942-889c-1858aa882a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "      <th>labels</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4754</th>\n",
       "      <td>sdss_ra=49.9154_dec=41.2302.png</td>\n",
       "      <td>0</td>\n",
       "      <td>49.9154</td>\n",
       "      <td>41.2302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>sdss_ra=49.4815_dec=41.434.png</td>\n",
       "      <td>0</td>\n",
       "      <td>49.4815</td>\n",
       "      <td>41.4340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>sdss_ra=49.5132_dec=41.3783.png</td>\n",
       "      <td>0</td>\n",
       "      <td>49.5132</td>\n",
       "      <td>41.3783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>sdss_ra=49.5247_dec=41.4305.png</td>\n",
       "      <td>0</td>\n",
       "      <td>49.5247</td>\n",
       "      <td>41.4305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>sdss_ra=49.7345_dec=41.6346.png</td>\n",
       "      <td>0</td>\n",
       "      <td>49.7345</td>\n",
       "      <td>41.6346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>sdss_ra=49.9932_dec=41.5479.png</td>\n",
       "      <td>1</td>\n",
       "      <td>49.9932</td>\n",
       "      <td>41.5479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5357</th>\n",
       "      <td>sdss_ra=49.9947_dec=41.75.png</td>\n",
       "      <td>1</td>\n",
       "      <td>49.9947</td>\n",
       "      <td>41.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5373</th>\n",
       "      <td>sdss_ra=49.9967_dec=41.3092.png</td>\n",
       "      <td>1</td>\n",
       "      <td>49.9967</td>\n",
       "      <td>41.3092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4501</th>\n",
       "      <td>sdss_ra=49.8825_dec=41.7447.png</td>\n",
       "      <td>1</td>\n",
       "      <td>49.8825</td>\n",
       "      <td>41.7447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>sdss_ra=49.9387_dec=41.2544.png</td>\n",
       "      <td>1</td>\n",
       "      <td>49.9387</td>\n",
       "      <td>41.2544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                files labels       ra      dec\n",
       "4754  sdss_ra=49.9154_dec=41.2302.png      0  49.9154  41.2302\n",
       "1405   sdss_ra=49.4815_dec=41.434.png      0  49.4815  41.4340\n",
       "1616  sdss_ra=49.5132_dec=41.3783.png      0  49.5132  41.3783\n",
       "1692  sdss_ra=49.5247_dec=41.4305.png      0  49.5247  41.4305\n",
       "3312  sdss_ra=49.7345_dec=41.6346.png      0  49.7345  41.6346\n",
       "...                               ...    ...      ...      ...\n",
       "5338  sdss_ra=49.9932_dec=41.5479.png      1  49.9932  41.5479\n",
       "5357    sdss_ra=49.9947_dec=41.75.png      1  49.9947  41.7500\n",
       "5373  sdss_ra=49.9967_dec=41.3092.png      1  49.9967  41.3092\n",
       "4501  sdss_ra=49.8825_dec=41.7447.png      1  49.8825  41.7447\n",
       "4931  sdss_ra=49.9387_dec=41.2544.png      1  49.9387  41.2544\n",
       "\n",
       "[246 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCC_list = downSampleDf1['files'].to_list()\n",
    "columnLength = len(PCC_list)\n",
    "ra_list = [None] * columnLength\n",
    "dec_list = [None] * columnLength\n",
    "for i in range(columnLength):\n",
    "    splitted = PCC_list[i].split('=')\n",
    "    ra_list[i] = float(splitted[1][:-4])\n",
    "    dec_list[i] = float(splitted[2][:-4])\n",
    "\n",
    "downSampleDf1['ra'] = ra_list\n",
    "downSampleDf1['dec'] = dec_list\n",
    "downSampleDf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d45742e0-94cc-49d3-b182-91c7d4852f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233, 23)\n",
      "(233, 23)\n"
     ]
    }
   ],
   "source": [
    "searchDf = pd.read_csv('../Sheets/SpecSearchNoCuts.csv')\n",
    "print(searchDf.shape)\n",
    "searchDf = searchDf.drop_duplicates(subset = 'objID') # sometimes SDSS has some objID duplicates\n",
    "print(searchDf.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96bd48d2-3279-4594-a6ff-e224bff07b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specbgs: 117\n",
      "specmems: 116\n",
      "total specs 233\n",
      "True\n",
      "pccbgs: 123\n",
      "pccmems: 123\n",
      "total pccs: 246\n",
      "True\n",
      "Total: 479 \n"
     ]
    }
   ],
   "source": [
    "# pcc_crossDf = pcc_crossDf.drop_duplicates(subset = 'objID')\n",
    "\n",
    "## Members 0.01 < spec-z < 0.033, else are NonMembers \n",
    "specMembers = searchDf['z'].between(0.01, 0.033)\n",
    "specNonMembers = np.invert(specMembers)\n",
    "\n",
    "searchDf_specMembers = searchDf.loc[specMembers].copy()\n",
    "searchDf_specMembers['labels'] = np.ones(int(searchDf_specMembers.shape[0]), dtype = int)\n",
    "\n",
    "searchDf_specNonMembers = searchDf.loc[specNonMembers].copy()\n",
    "searchDf_specNonMembers['labels'] = np.zeros(int(searchDf_specNonMembers.shape[0]), dtype = int)\n",
    "\n",
    "pcc_nonMembers = downSampleDf1.loc[(downSampleDf1['labels'] == '0')]\n",
    "pcc_Members = downSampleDf1.loc[(downSampleDf1['labels'] == '1')]\n",
    "\n",
    "## sanity checks\n",
    "print('specbgs:', searchDf_specNonMembers.shape[0])\n",
    "print('specmems:', searchDf_specMembers.shape[0])\n",
    "print('total specs', searchDf_specNonMembers.shape[0] + searchDf_specMembers.shape[0])\n",
    "print(searchDf_specNonMembers.shape[0] + searchDf_specMembers.shape[0] == searchDf.shape[0])\n",
    "\n",
    "print('pccbgs:', pcc_nonMembers.shape[0])\n",
    "print('pccmems:', pcc_Members.shape[0])\n",
    "print('total pccs:', pcc_nonMembers.shape[0] + pcc_Members.shape[0])\n",
    "print(pcc_nonMembers.shape[0] + pcc_Members.shape[0] == downSampleDf1.shape[0])\n",
    "\n",
    "print(f'Total: {searchDf_specNonMembers.shape[0] + searchDf_specMembers.shape[0] + pcc_nonMembers.shape[0] + pcc_Members.shape[0]} ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db10bd08-8152-4c18-86ba-18df47129944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcc_crossDf[['objID', 'ra', 'dec']]\n",
    "trainObjs = pd.concat([pcc_nonMembers[['ra', 'dec', 'labels']],\n",
    "                      pcc_Members[['ra', 'dec', 'labels']],\n",
    "                      searchDf_specNonMembers[['ra', 'dec', 'labels']],\n",
    "                      searchDf_specMembers[['ra', 'dec', 'labels']]],\n",
    "                      keys = ('PCC_Bg', 'PCC_Mems', 'Spec_Bg', 'Spec_Mems')) # want to preserve where these come from\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e688c70-62f0-4100-8f05-c6829a611eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainObjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59d0cc49-df2a-4d63-b98d-17db6f77611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainObjs['dec']['PCC_Bg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7d6db9d-ea46-4809-87c6-2b0f958644f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # trainObjs = trainObjs.drop_duplicates(subset = 'objID')\n",
    "# trainObjs['labels'] = pd.to_numeric(trainObjs['labels'], downcast='integer')\n",
    "\n",
    "# img_width, img_height = 200, 200\n",
    "# SkyServer_DataRelease = 'DR16'\n",
    "\n",
    "# dirName = 'PCC-and-SpecSearch'\n",
    "# outDir = os.path.join('..', 'Images', dirName)\n",
    "\n",
    "# fileList = list()\n",
    "# if not os.path.exists(outDir):\n",
    "#    os.makedirs(outDir)\n",
    "    \n",
    "# if len(glob.glob(os.path.join(outDir, '*.png'))) == trainObjs.shape[0]:\n",
    "#     print('Skipping Populate')\n",
    "# else:\n",
    "#     # for id, r, d in zip(searchDf['objID'], trainObjs['ra'], trainObjs['dec']):\n",
    "#     for r, d, l in zip(trainObjs['ra'], trainObjs['dec'], trainObjs['labels']):\n",
    "#         img_array = SkyServer.getJpegImgCutout(ra=r, dec=d, width=img_width, height=img_height, scale=0.1, \n",
    "#                                      dataRelease=SkyServer_DataRelease)\n",
    "#         # print(f'{id}-label={labeler(z)}')\n",
    "#         # outPicTemplate = f'{id}-label={labeler(z)}.png'\n",
    "#         outPicTemplate = f'sdss_ra={r}_dec={d}-label={l}.png'\n",
    "        \n",
    "#         img0 = PIL.Image.fromarray(img_array, 'RGB')\n",
    "#         img0.save(f'{outDir}/{outPicTemplate}')\n",
    "#         fileList.append(f'{outPicTemplate}')\n",
    "\n",
    "# print(f'Finished populate with {len(fileList)} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d4d021e-c4f4-4d25-bab5-c1099210d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # trainObjs = trainObjs.drop_duplicates()\n",
    "# trainObjs['files'] = fileList\n",
    "# trainObjs.to_csv('../Sheets/trainObjects.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ff0b0f4-8af0-483b-b3e0-19436bff5d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4bd0b14-e317-495c-a39e-e90fcb7c2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove red contaminants\n",
    "# # downFiles = downSampleDf1['files']\n",
    "# downFiles = trainObjs['files']\n",
    "# # trainObjs['files'] = downFiles\n",
    "# # downFiles = trainObjs['files']\n",
    "# redPercent = [None]*len(downFiles)\n",
    "\n",
    "# counter = 0\n",
    "# # workDir = '../Images/SDSS-png/'\n",
    "# # workDir = os.path.join('..', 'Images', 'SDSS-png')\n",
    "# workDir = outDir\n",
    "\n",
    "# # lower boundary RED color range values; Hue (0 - 10)\n",
    "# lower1 = np.array([0, 80, 20])\n",
    "# upper1 = np.array([10, 255, 255])\n",
    " \n",
    "# # upper boundary RED color range values; Hue (160 - 180)\n",
    "# lower2 = np.array([160, 100, 20])\n",
    "# upper2 = np.array([179, 255, 255])\n",
    "\n",
    "# for i, x in enumerate(downFiles):\n",
    "#     # testImgPath = x\n",
    "#     testImgPath = os.path.join(workDir, x)\n",
    "#     image = cv2.imread(testImgPath)\n",
    "#     result = image.copy()\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "#     # check image for pixels on the lower and upper end of hsv (red is weird for hsv)\n",
    "#     lower_mask = cv2.inRange(image, lower1, upper1)\n",
    "#     upper_mask = cv2.inRange(image, lower2, upper2)\n",
    "#     full_mask = lower_mask + upper_mask;\n",
    "\n",
    "#     result = cv2.bitwise_and(result, result, mask=full_mask)\n",
    "#     dim = np.shape(full_mask)[0]\n",
    "#     counts = np.count_nonzero(full_mask)\n",
    "#     percent = 100*counts/dim**2\n",
    "#     redPercent[i] = percent\n",
    "#     subtitle_string = f'{percent}% of the image is red'\n",
    "#     filename = testImgPath.split('\\\\')[-1]\n",
    "\n",
    "# trainObjs['reds'] = redPercent # add new column of the red percentage of an image\n",
    "# # downSampleDf1\n",
    "# redList = (trainObjs['reds'] >= 50) # percentage threshold of how much red is in the image\n",
    "# # downSampleDf1.shape\n",
    "# df_filtered = trainObjs[trainObjs['reds'] <= 50]\n",
    "\n",
    "# ## TODO -- Why are these different per run?\n",
    "# print(f'{trainObjs.shape[0]} images before filtering')\n",
    "# print(f'{df_filtered.shape[0]} images after filtering')\n",
    "\n",
    "# ## Uncomment to see red images \n",
    "# # redInds = np.where(redList)[0] # the indices of the hot pixel images to be removed\n",
    "# # print(len(redInds))\n",
    "# # for n in redInds:\n",
    "# #     red = downSampleDf1['files'].to_list()[n]\n",
    "# #     imStr = '../Images/SDSS-png/' + red\n",
    "# #     im = cv2.imread(imStr)[:,:,::-1] # [:,:,::-1] switches rgb to bgr and vice versa\n",
    "# #     plt.figure\n",
    "# #     plt.imshow(im)\n",
    "# #     plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67b30945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>labels</th>\n",
       "      <th>files</th>\n",
       "      <th>reds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCC_Bg</td>\n",
       "      <td>3848</td>\n",
       "      <td>49.803800</td>\n",
       "      <td>41.581100</td>\n",
       "      <td>0</td>\n",
       "      <td>sdss_ra=49.8038_dec=41.5811-label=0.png</td>\n",
       "      <td>2.1575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PCC_Bg</td>\n",
       "      <td>2340</td>\n",
       "      <td>49.618400</td>\n",
       "      <td>41.454600</td>\n",
       "      <td>0</td>\n",
       "      <td>sdss_ra=49.6184_dec=41.4546-label=0.png</td>\n",
       "      <td>1.7875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PCC_Bg</td>\n",
       "      <td>5416</td>\n",
       "      <td>50.002800</td>\n",
       "      <td>41.338400</td>\n",
       "      <td>0</td>\n",
       "      <td>sdss_ra=50.0028_dec=41.3384-label=0.png</td>\n",
       "      <td>3.4875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCC_Bg</td>\n",
       "      <td>5239</td>\n",
       "      <td>49.981400</td>\n",
       "      <td>41.420200</td>\n",
       "      <td>0</td>\n",
       "      <td>sdss_ra=49.9814_dec=41.4202-label=0.png</td>\n",
       "      <td>1.5600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCC_Bg</td>\n",
       "      <td>524</td>\n",
       "      <td>49.334200</td>\n",
       "      <td>41.330000</td>\n",
       "      <td>0</td>\n",
       "      <td>sdss_ra=49.3342_dec=41.33-label=0.png</td>\n",
       "      <td>8.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>Spec_Mems</td>\n",
       "      <td>267</td>\n",
       "      <td>50.622746</td>\n",
       "      <td>41.050445</td>\n",
       "      <td>1</td>\n",
       "      <td>sdss_ra=50.622745654887_dec=41.0504450153301-l...</td>\n",
       "      <td>4.6375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>Spec_Mems</td>\n",
       "      <td>271</td>\n",
       "      <td>50.694593</td>\n",
       "      <td>41.941230</td>\n",
       "      <td>1</td>\n",
       "      <td>sdss_ra=50.6945934204297_dec=41.9412303787257-...</td>\n",
       "      <td>18.0575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>Spec_Mems</td>\n",
       "      <td>272</td>\n",
       "      <td>49.705849</td>\n",
       "      <td>40.827589</td>\n",
       "      <td>1</td>\n",
       "      <td>sdss_ra=49.7058490785794_dec=40.8275889370729-...</td>\n",
       "      <td>2.3425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Spec_Mems</td>\n",
       "      <td>273</td>\n",
       "      <td>49.112658</td>\n",
       "      <td>41.180216</td>\n",
       "      <td>1</td>\n",
       "      <td>sdss_ra=49.112658441068_dec=41.1802159335769-l...</td>\n",
       "      <td>5.7725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>Spec_Mems</td>\n",
       "      <td>274</td>\n",
       "      <td>49.470275</td>\n",
       "      <td>40.897244</td>\n",
       "      <td>1</td>\n",
       "      <td>sdss_ra=49.4702754784142_dec=40.8972443909435-...</td>\n",
       "      <td>6.7850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Unnamed: 1         ra        dec  labels  \\\n",
       "0       PCC_Bg        3848  49.803800  41.581100       0   \n",
       "1       PCC_Bg        2340  49.618400  41.454600       0   \n",
       "2       PCC_Bg        5416  50.002800  41.338400       0   \n",
       "3       PCC_Bg        5239  49.981400  41.420200       0   \n",
       "4       PCC_Bg         524  49.334200  41.330000       0   \n",
       "..         ...         ...        ...        ...     ...   \n",
       "453  Spec_Mems         267  50.622746  41.050445       1   \n",
       "454  Spec_Mems         271  50.694593  41.941230       1   \n",
       "455  Spec_Mems         272  49.705849  40.827589       1   \n",
       "456  Spec_Mems         273  49.112658  41.180216       1   \n",
       "457  Spec_Mems         274  49.470275  40.897244       1   \n",
       "\n",
       "                                                 files     reds  \n",
       "0              sdss_ra=49.8038_dec=41.5811-label=0.png   2.1575  \n",
       "1              sdss_ra=49.6184_dec=41.4546-label=0.png   1.7875  \n",
       "2              sdss_ra=50.0028_dec=41.3384-label=0.png   3.4875  \n",
       "3              sdss_ra=49.9814_dec=41.4202-label=0.png   1.5600  \n",
       "4                sdss_ra=49.3342_dec=41.33-label=0.png   8.2500  \n",
       "..                                                 ...      ...  \n",
       "453  sdss_ra=50.622745654887_dec=41.0504450153301-l...   4.6375  \n",
       "454  sdss_ra=50.6945934204297_dec=41.9412303787257-...  18.0575  \n",
       "455  sdss_ra=49.7058490785794_dec=40.8275889370729-...   2.3425  \n",
       "456  sdss_ra=49.112658441068_dec=41.1802159335769-l...   5.7725  \n",
       "457  sdss_ra=49.4702754784142_dec=40.8972443909435-...   6.7850  \n",
       "\n",
       "[458 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_filtered.to_csv('../Sheets/trainObjects_filtered.csv')\n",
    "df_filtered = pd.read_csv('../Sheets/trainObjects_filtered.csv')\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a085f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to clean /rotations-png/test and /rotations-png/train/ every run \n",
    "imgDirectory = '../Images/rotations-png'\n",
    "testPath = os.path.join(imgDirectory, 'test', '*')\n",
    "testImgs = glob.glob(testPath)\n",
    "trainPath = os.path.join(imgDirectory, 'train', '*')\n",
    "trainImgs = glob.glob(trainPath)\n",
    "\n",
    "# testImgs = glob.glob(testDir)\n",
    "for x in testImgs:\n",
    "    os.remove(x)\n",
    "# can't do it all in one loop since in wrong dir\n",
    "for y in trainImgs:\n",
    "    os.remove(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c759874-55c1-46f5-bb79-5984bb3d1bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate Rotation data\n",
    "\n",
    "def applyRotations(originalDf, outDir, greyFlag):\n",
    "\n",
    "    # files and labels as numpy arrays\n",
    "    files = originalDf['files'].to_numpy()\n",
    "    label = originalDf['labels'].to_numpy()\n",
    "    \n",
    "    rotDir = '../Images/rotations-png'\n",
    "    # originalDir = '../Images/SDSS-png/'\n",
    "    originalDir = '../Images/PCC-and-SpecSearch/'\n",
    "    # originalDir = workDir\n",
    "\n",
    "    rotFilenames = list()\n",
    "    rotLabels = list()\n",
    "\n",
    "    #angle = [90, 180, 270, 360]\n",
    "    angle = [30, 45, 60, 90, 120, 135, 150, 180, 210, 225, 240, 270, 300, 315, 330, 360]\n",
    "\n",
    "    # Use PIL to rotate image on angles in list\n",
    "    for ang in angle:\n",
    "        for f, l in zip(files, label):\n",
    "            imgString = originalDir + f\n",
    "            im = PIL.Image.open(imgString)\n",
    "            \n",
    "            if greyFlag == True:\n",
    "                im = im.convert('L')\n",
    "            out = im.rotate(ang)\n",
    "           \n",
    "            # generated filename\n",
    "            # outString = f'{rotDir}/{outDir}/{f[:-5]}_rot{ang}_label={l}.png'\n",
    "            outString = f'{rotDir}/{outDir}/{f[:-5]}_rot{ang}.png'\n",
    "            \n",
    "            # filename relative to working directory\n",
    "            # dfString = f'{outDir}/{f[:-5]}_rot{ang}_label={l}.png'\n",
    "            dfString = f'{outDir}/{f[:-5]}_rot{ang}.png'\n",
    "\n",
    "            out.save(outString)\n",
    "            rotFilenames.append(dfString)\n",
    "            rotLabels.append(l)\n",
    "\n",
    "            rotationDf = pd.DataFrame({'files': rotFilenames,\n",
    "                                    'labels': rotLabels})\n",
    "\n",
    "    return(rotationDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48b0eb4f-18e9-4652-8e9f-788c58210479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filtered['labels'] = pd.to_numeric(df_filtered['labels'], downcast='integer')\n",
    "# df_filtered['labels'] = df_filtered['labels'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8145bd00-1309-4065-bd8d-5888cb7d8bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train directory populated\n",
      "test directory populated\n"
     ]
    }
   ],
   "source": [
    "# # Train/Test Split \n",
    "X = df_filtered['files']\n",
    "y = df_filtered['labels']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "trainDf = pd.DataFrame({'files' : X_train,\n",
    "                        'labels': y_train})\n",
    "testDf = pd.DataFrame({'files' : X_test,\n",
    "                        'labels': y_test})\n",
    "\n",
    "greyFlag = False\n",
    "trainDf_rot = applyRotations(trainDf, 'train', greyFlag)\n",
    "print('train directory populated')\n",
    "testDf_rot = applyRotations(testDf, 'test', greyFlag)\n",
    "print('test directory populated')\n",
    "# trainDf.to_csv('trainDf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4b958c4-d43e-489e-ad2c-bd7e0dae91b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkBalance(trainDf)\n",
    "# checkBalance(trainDf_rot)\n",
    "# trainDf_rot\n",
    "trainDf_rot['labels'] = trainDf_rot['labels'].astype(str)\n",
    "\n",
    "# testDf_rot\n",
    "testDf_rot['labels'] = testDf_rot['labels'].astype(str)\n",
    "# trainDf_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c5ff4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4116 validated image filenames belonging to 2 classes.\n",
      "Found 1372 validated image filenames belonging to 2 classes.\n",
      "Found 1840 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# # Create datasets with flow from dataframe\n",
    "IMG_WIDTH = 200\n",
    "IMG_HEIGHT = 200\n",
    "TRAIN_BATCH_SIZE = 40\n",
    "VAL_BATCH_SIZE = 40\n",
    "\n",
    "#imgDirectory = \"./rotations/\"\n",
    "imgDirectory = \"../Images/rotations-png/\"\n",
    "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=trainDf_rot,\n",
    "directory=imgDirectory,\n",
    "x_col=\"files\",\n",
    "y_col=\"labels\",\n",
    "subset=\"training\",\n",
    "batch_size=TRAIN_BATCH_SIZE, # divisibility\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "# class_mode=\"binary\",\n",
    "target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
    "\n",
    "validation_generator=datagen.flow_from_dataframe(\n",
    "dataframe=trainDf_rot,\n",
    "directory=imgDirectory,\n",
    "x_col=\"files\",\n",
    "y_col=\"labels\",\n",
    "subset=\"validation\",\n",
    "batch_size=VAL_BATCH_SIZE,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "# class_mode=\"binary\",\n",
    "target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=testDf_rot,\n",
    "directory=imgDirectory,\n",
    "x_col=\"files\",\n",
    "y_col=None,\n",
    "batch_size=1,\n",
    "seed=42,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "target_size=(IMG_WIDTH,IMG_HEIGHT))\n",
    "\n",
    "\n",
    "# # ResNet50 Model\n",
    "#\n",
    "# https://github.com/suvoooo/Learn-TensorFlow/blob/master/resnet/Implement_Resnet_TensorFlow.ipynb\n",
    "\n",
    "def res_identity(x, filters):\n",
    "    x_skip = x # this will be used for addition with the residual block\n",
    "    f1, f2 = filters\n",
    "\n",
    "    #first block\n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    #second block # bottleneck (but size kept same with padding)\n",
    "    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    # third block activation used after adding the input\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # x = Activation(activations.relu)(x)\n",
    "\n",
    "    # add the input\n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def res_conv(x, s, filters):\n",
    "\n",
    "    x_skip = x\n",
    "    f1, f2 = filters\n",
    "\n",
    "    # first block\n",
    "    x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    # when s = 2 then it is like downsizing the feature map\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    # second block\n",
    "    x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    #third block\n",
    "    x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # shortcut\n",
    "    x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=l2(0.001))(x_skip)\n",
    "    x_skip = BatchNormalization()(x_skip)\n",
    "\n",
    "    # add\n",
    "    x = Add()([x, x_skip])\n",
    "    x = Activation(activations.relu)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet50():\n",
    "\n",
    "    input_im = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3)) \n",
    "    x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
    "\n",
    "    # 1st stage\n",
    "    # here we perform maxpooling, see the figure above\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    #2nd stage\n",
    "    # frm here on only conv block and identity block, no pooling\n",
    "\n",
    "    x = res_conv(x, s=1, filters=(64, 256))\n",
    "    x = res_identity(x, filters=(64, 256))\n",
    "    x = res_identity(x, filters=(64, 256))\n",
    "\n",
    "    # 3rd stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "\n",
    "    # 4th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "\n",
    "    # 5th stage\n",
    "\n",
    "    x = res_conv(x, s=2, filters=(512, 2048))\n",
    "    x = res_identity(x, filters=(512, 2048))\n",
    "    x = res_identity(x, filters=(512, 2048))\n",
    "\n",
    "    # ends with average pooling and dense connection\n",
    "\n",
    "    x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(2, activation='softmax', kernel_initializer='he_normal')(x) #multi-class\n",
    "\n",
    "    # define the model\n",
    "\n",
    "    model = Model(inputs=input_im, outputs=x, name='Resnet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4104fccd-acb9-46e0-bc67-6e75171df45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet15():\n",
    "\n",
    "    input_im = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3)) \n",
    "    x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
    "\n",
    "    # 1st stage\n",
    "    # here we perform maxpooling, see the figure above\n",
    "\n",
    "    x = Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activations.relu)(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "    # 2nd stage\n",
    "    # from here on only conv block and identity block, no pooling\n",
    "\n",
    "    x = res_conv(x, s=1, filters=(32, 128))\n",
    "    x = res_identity(x, filters=(32, 128))\n",
    "\n",
    "    # 3rd stage\n",
    "    x = res_conv(x, s=2, filters=(64, 256))\n",
    "    x = res_identity(x, filters=(64, 256))\n",
    "\n",
    "    # 4th stage\n",
    "    x = res_conv(x, s=2, filters=(128, 512))\n",
    "    x = res_identity(x, filters=(128, 512))\n",
    "\n",
    "    # 5th stage\n",
    "    x = res_conv(x, s=2, filters=(256, 1024))\n",
    "    x = res_identity(x, filters=(256, 1024))\n",
    "\n",
    "    # ends with average pooling and dense connection\n",
    "    x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(2, activation='softmax', kernel_initializer='he_normal')(x) # multi-class\n",
    "\n",
    "    # define the model\n",
    "    model = Model(inputs=input_im, outputs=x, name='Resnet15')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dc8cf37-f171-45cc-9264-8aa7eaf319e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number(modelStr):\n",
    "    modelStr = modelStr.split('.')\n",
    "    modelNum = modelStr[-2][-1]\n",
    "    return(int(modelNum))\n",
    "\n",
    "allModels = os.path.join('..', 'Models', '*.h5')\n",
    "modelFiles = glob.glob(allModels)\n",
    "\n",
    "result = map(number, modelFiles)\n",
    "modelNum = max(list(result)) + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38e1963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_model = resnet50()\n",
    "cnn_model = resnet15()\n",
    "# BATCH_SIZE = 1\n",
    "\n",
    "modelName = f'pcc_resnet15_{modelNum}' # template is currently pcc_resnet50_X, where X is the iteration of the model\n",
    "modelStr = os.path.join('..', 'Models', modelName) \n",
    "\n",
    "### Hyperparameters ###\n",
    "n_epochs = 5\n",
    "# init_lr = 7.5e-2\n",
    "init_lr = 9e-2\n",
    "# decay_rate = 0.99\n",
    "decay_rate = 0.30\n",
    "# decay_steps = 100_000\n",
    "decay_steps = 1000\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                    initial_learning_rate = init_lr,\n",
    "                    decay_steps = decay_steps,\n",
    "                    decay_rate = decay_rate)\n",
    "\n",
    "\n",
    "cnn_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule),\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = cnn_model.fit(train_generator,\n",
    "                        epochs = n_epochs,\n",
    "                        callbacks = [es],\n",
    "                        verbose = 1,\n",
    "                        validation_data=validation_generator)\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# learning_rate = history.history['']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce8760",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(12, 10))\n",
    "\n",
    "ax[0].set_title('Training Accuracy vs. Epochs')\n",
    "ax[0].plot(train_accuracy, 'o-', label='Train Accuracy')\n",
    "ax[0].plot(val_accuracy, 'o-', label='Validation Accuracy')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].legend(loc='best')\n",
    "ax[0].grid()\n",
    "\n",
    "ax[1].set_title('Training/Validation Loss vs. Epochs')\n",
    "ax[1].plot(train_loss, 'o-', label='Train Loss')\n",
    "ax[1].plot(val_loss, 'o-', label='Validation Loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].set_ylim([-1, 100])\n",
    "ax[1].legend(loc='best')\n",
    "\n",
    "# ax[2].set_title('Learning Rate vs. Epochs')\n",
    "# ax[2].plot(learning_rate, 'o-', label='Learning Rate')\n",
    "# ax[2].set_xlabel('Epochs')\n",
    "# ax[2].set_ylabel('Learning Rate')\n",
    "# ax[2].legend(loc='best')\n",
    "\n",
    "# ax[3].set_title('Loss vs learning rate')\n",
    "# # ax[3].plot(learning_rate, 'o-', label='Learning Rate')\n",
    "# ax[3].plot(learning_rate, train_loss, 'o-', label='Train Loss')\n",
    "# ax[3].plot(learning_rate, val_loss, 'o-', label='Validation Loss')\n",
    "# ax[3].set_ylabel('Loss')\n",
    "# ax[3].set_xlabel('Learning Rate')\n",
    "# ax[3].legend(loc='best')\n",
    "\n",
    "plt.suptitle(f'Initial LR = {init_lr} Decay Rate = {decay_rate}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{modelName}-train-report_init-lr={init_lr}_decay-rate={decay_rate}_offrots.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(12, 10))\n",
    "# idx = 0\n",
    "\n",
    "# for i in range(2):\n",
    "#     for j in range(5):\n",
    "#         predicted_label = unique_labels[np.argmax(predictions[idx])]\n",
    "#         ax[i, j].set_title(f\"{predicted_label}\", fontsize=10)\n",
    "#         ax[i, j].imshow(test_generator[idx][0])\n",
    "\n",
    "#         ax[i, j].axis(\"off\")\n",
    "#         idx += 1\n",
    "\n",
    "# # plt.tight_layout()\n",
    "# plt.suptitle(\"Test Dataset Predictions\", fontsize=20)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# In[34]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3c5d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cnn_model.predict(test_generator)\n",
    "# test_loss, test_accuracy = cnn_model.evaluate(validation_generator, batch_size=1) # needs to be divisible\n",
    "test_loss, test_accuracy = cnn_model.evaluate(test_generator, batch_size=1) # needs to be divisible\n",
    "\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = testDf_rot['labels'] # this needs to be checked if you change the input dataframes\n",
    "y_true = y_true.tolist()\n",
    "# len(y_pred) == len(y_true)\n",
    "unique_labels = {value: key for key, value in train_generator.class_indices.items()}\n",
    "\n",
    "# print(\"Label Mappings for classes present in the training and validation datasets\\n\")\n",
    "# for key, value in unique_labels.items():\n",
    "#     print(f\"{key} : {value}\")\n",
    "\n",
    "# function to return key for any value\n",
    "def get_key(val):\n",
    "    for key, value in unique_labels.items():\n",
    "        if val == value:\n",
    "            return key\n",
    "\n",
    "    return \"key doesn't exist\"\n",
    "\n",
    "Y_true = []\n",
    "# for i in range(len(y_true)): # This was the original way to do it -- be careful, this only solved a mismatch and could be wrong\n",
    "for i in range(len(y_pred)):\n",
    "    Y_true.append(get_key(y_true[i]))\n",
    "\n",
    "cf_mtx = confusion_matrix(Y_true, y_pred)\n",
    "\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cf_mtx.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cf_mtx.flatten()/np.sum(cf_mtx)]\n",
    "box_labels = [f\"{v1}\\n({v2})\" for v1, v2 in zip(group_counts, group_percentages)]\n",
    "box_labels = np.asarray(box_labels).reshape(2, 2)\n",
    "\n",
    "\n",
    "# cf_mtx.sum()\n",
    "\n",
    "y_true = np.array([int(x) for x in y_true]) # cast to np array for type consistency with y_pred\n",
    "errors = (y_true - y_pred != 0) # everywhere the numbers don't match\n",
    "y_true_errors = y_true[errors]\n",
    "y_pred_errors = y_pred[errors]\n",
    "\n",
    "test_images = test_generator.filenames\n",
    "test_img_err = np.asarray(test_images)[errors]\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=3, ncols=5, figsize=(12, 10))\n",
    "# idx = 0\n",
    "\n",
    "hits = (y_true - y_pred == 0)\n",
    "y_true_hits = y_true[hits]\n",
    "y_pred_hits = y_pred[hits]\n",
    "\n",
    "test_img_hits = np.asarray(test_images)[hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce50a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 10))\n",
    "# sns.heatmap(cf_mtx, xticklabels=labels.values(), yticklabels=labels.values(),\n",
    "#            cmap=\"YlGnBu\", fmt=\"\", annot=box_labels)\n",
    "sns.heatmap(cf_mtx, cmap=\"YlGnBu\", fmt=\"\", annot=box_labels)\n",
    "plt.xlabel('Predicted Classes')\n",
    "plt.ylabel('True Classes')\n",
    "#plt.show()\n",
    "\n",
    "plt.title(f\"Test Accuracy: {test_accuracy*100:.2f}\")\n",
    "plt.savefig(f'{modelName}-confusion-matrix_init-lr={init_lr}_decay-rate={decay_rate}_offrots.png')\n",
    "\n",
    "# for i in range(3):\n",
    "#     for j in range(5):\n",
    "#         idx = np.random.randint(0, len(test_img_err))\n",
    "#         true_index = y_true_errors[idx]\n",
    "#         true_label = unique_labels[true_index]\n",
    "#         predicted_index = y_pred_errors[idx]\n",
    "#         predicted_label = unique_labels[predicted_index]\n",
    "#         ax[i, j].set_title(f\"True Label: {true_label} \\n Predicted Label: {predicted_label}\")\n",
    "#         ax[i, j].imshow(test_generator[idx][0])\n",
    "#         ax[i, j].axis(\"off\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.suptitle('Wrong Predictions made on test set', fontsize=15)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=3, ncols=5, figsize=(12, 10))\n",
    "# idx = 0\n",
    "\n",
    "# for i in range(3):\n",
    "#     for j in range(5):\n",
    "#         idx = np.random.randint(0, len(test_img_hits))\n",
    "#         true_index = y_true_hits[idx]\n",
    "#         true_label = unique_labels[true_index]\n",
    "#         predicted_index = y_pred_hits[idx]\n",
    "#         predicted_label = unique_labels[predicted_index]\n",
    "#         ax[i, j].set_title(f\"True Label: {true_label} \\n Predicted Label: {predicted_label}\")\n",
    "#         ax[i, j].imshow(test_generator[idx][0])\n",
    "#         ax[i, j].axis(\"off\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.suptitle('True Predictions made on test set', fontsize=15)\n",
    "# plt.show()\n",
    "\n",
    "# # End result:\n",
    "print(f'Init conds:')\n",
    "print(f'init lr: {init_lr}, decay rate: {decay_rate}, decay steps: {decay_steps}')\n",
    "print(f\"Test Loss:     {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "## save model weights ## \n",
    "cnn_model.save(f'../Models/{modelStr}.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc136b72-095f-4598-8ce9-3e61c22b6447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "# model = models.load_model(f'../Models/{modelStr}.h5')\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def make_prediction(img_path):\n",
    "    # Load and preprocess the input image\n",
    "    # img_path = '../Images/PCC-and-SpecSearch/sdss_ra=48.9999795273873_dec=41.2875102706543-label=0.png'\n",
    "    img = image.load_img(img_path, target_size=(IMG_WIDTH, IMG_HEIGHT))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array /= 255.  # Normalize pixel values (assuming your model was trained with normalized inputs)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = cnn_model.predict(img_array)\n",
    "    \n",
    "    # Postprocess predictions\n",
    "    predicted_class = np.argmax(predictions)  # Assuming your model outputs class probabilities\n",
    "    class_labels = ['0', '1']  # Define your class labels accordingly\n",
    "    predicted_label = class_labels[predicted_class]\n",
    "    \n",
    "    # print('Predicted class:', predicted_label)\n",
    "    return(predicted_label)\n",
    "\n",
    "trainImgs = os.path.join('..', 'Images', 'PCC-and-SpecSearch', '*.png')\n",
    "\n",
    "counter = 0\n",
    "for ind, x in enumerate(glob.glob(trainImgs)):\n",
    "    if make_prediction(x) != x[-5]:\n",
    "        counter += 1\n",
    "\n",
    "print(counter)\n",
    "len(glob.glob(trainImgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e742bce8-66a8-4c03-82b5-1c6e1a3e8b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainObjs = trainObjs.reindex(columns=['labels', 'ra', 'dec'])\n",
    "trainObjs.to_csv('../Sheets/trainObjectsCrossMatch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1770f6b9-575c-4d1e-918b-286725510812",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainObjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea59c64a-ed6f-4206-9bb5-834e2cc5e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_crossMatch = pd.read_csv('../Sheets/trainObjectsCrossMatched.csv', skiprows = 1)\n",
    "train_crossMatch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efdef87-1a53-4022-a548-f3f0bbdba2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment for big pairplot:\n",
    "pairDf = train_crossMatch[['ra', 'dec', 'r', 'u_g', 'g_z', 'g_r', 'labels']]\n",
    "\n",
    "p1 = sns.pairplot(pairDf, corner = False, hue = 'labels')\n",
    "p1.map_diag(sns.histplot)\n",
    "p1.map_upper(sns.kdeplot)\n",
    "p1.savefig(f'../Images/{modelStr}-classifying-training-set.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d463cc69-c73f-4fed-80f0-d44d534f9441",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars = pairDf[['u_g', 'g_z', 'g_r']]\n",
    "y_vars = pairDf[['r']]\n",
    "y_lim = (y_vars.min()[0], y_vars.max()[0])\n",
    "\n",
    "f = sns.PairGrid(pairDf, hue=\"labels\", x_vars=x_vars, y_vars=y_vars, height = 3)\n",
    "# f.map_diag(sns.histplot, color=\".3\")\n",
    "f.map_offdiag(sns.scatterplot)\n",
    "f.add_legend()\n",
    "\n",
    "## y limits\n",
    "f.axes[0, 0].set_ylim(y_lim[::-1])\n",
    "\n",
    "# x limits\n",
    "f.axes[0, 0].set_xlim((0, 4))\n",
    "f.axes[0, 1].set_xlim((0, 4))\n",
    "f.axes[0, 2].set_xlim((0, 2.5))\n",
    "# f.axes[0, 1].set_xlim(modMagr_lim[::-1])\n",
    "# f.axes[0, 2].set_xlim(petroRad_r_lim)\n",
    "y_lim\n",
    "f.savefig(f'../Images/{modelStr}-Rmag-vs-color.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9725be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_layers = [None]*53 # 53 layers\n",
    "# ind = 0\n",
    "# for layer in cnn_model.layers:\n",
    "    \n",
    "#     # check for convolutional layer\n",
    "#     if 'conv' not in layer.name:\n",
    "#         continue\n",
    "        \n",
    "#     else:\n",
    "#         # get filter weights\n",
    "#         filters, biases = layer.get_weights()\n",
    "#         print(layer.name, filters.shape, layer.output.shape)\n",
    "#         conv_layers[ind] = layer.name\n",
    "#         ind += 1\n",
    "# len(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626ffbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters, biases = cnn_model.layers[9].get_weights()\n",
    "\n",
    "# # normalize filter values to 0-1 so we can visualize them\n",
    "# f_min, f_max = filters.min(), filters.max()\n",
    "# filters = (filters - f_min) / (f_max - f_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aec2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot first few filters\n",
    "# n_filters, ix = 6, 1\n",
    "# for i in range(n_filters):\n",
    "#     # get the filter\n",
    "#     f = filters[:, :, :, i]\n",
    "    \n",
    "# # plot each channel separately\n",
    "# for j in range(3):\n",
    "#     # specify subplot and turn of axis\n",
    "#     ax = plt.subplot(n_filters, 3, ix)\n",
    "#     ax.set_xticks([])\n",
    "#     ax.set_yticks([])\n",
    "#     # plot filter channel in grayscale\n",
    "#     plt.imshow(f[:, :, j], cmap='gray')\n",
    "#     ix += 1\n",
    "#     # show the figure\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f52850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## are these redundant?? TODO -- Clean!\n",
    "\n",
    "# trainPath = os.path.join('rotations-png', 'train', '*')\n",
    "# trainImgs = glob.glob(trainPath)\n",
    "# testPath = os.path.join('rotations-png', 'test', '*')\n",
    "# testImgs = glob.glob(testPath)\n",
    "\n",
    "# maps_model = Model(cnn_model.inputs, outputs=cnn_model.layers[9].output)\n",
    "# maps_model.summary()\n",
    "# exImage = load_img(testImgs[0])\n",
    "# copyImg = exImage.copy()\n",
    "# exImage = img_to_array(exImage)\n",
    "# exImage = np.expand_dims(exImage, axis = 0)\n",
    "# exImage = preprocess_input(exImage)\n",
    "\n",
    "# feature_maps = maps_model.predict(exImage)\n",
    "# # feature_maps\n",
    "# # np.shape(exImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fca431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# square = 8\n",
    "# ix = 1\n",
    "# for _ in range(square):\n",
    "#     for _ in range(square):\n",
    "#         # specify subplot and turn of axis\n",
    "#         ax = plt.subplot(square, square, ix)\n",
    "#         ax.set_xticks([])\n",
    "#         ax.set_yticks([])\n",
    "#         # plot filter channel in grayscale\n",
    "#         plt.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n",
    "# #         plt.imshow((feature_maps[0, :, :, ix-1]))\n",
    "#         ix += 1\n",
    "# # show the figure\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28b4c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(copyImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f61c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(testImgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b6bb19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
